"""
BrainOps AI OS - Continuous Awareness System

Provides real-time monitoring and awareness of:
- Internal system health (CPU, memory, database, APIs)
- External environment (weather, market, competitors)
- Business metrics (revenue, leads, customers)
- Anomaly detection and predictive alerts
- Sensory processing pipeline
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, TYPE_CHECKING
from enum import Enum
from dataclasses import dataclass, field
from collections import deque
import asyncpg
import psutil
import httpx

if TYPE_CHECKING:
    from .metacognitive_controller import MetacognitiveController

logger = logging.getLogger(__name__)


class AlertSeverity(str, Enum):
    """Alert severity levels"""
    CRITICAL = "critical"
    WARNING = "warning"
    INFO = "info"
    DEBUG = "debug"


class SensorType(str, Enum):
    """Types of sensors in the awareness system"""
    SYSTEM_HEALTH = "system_health"
    DATABASE = "database"
    API_PERFORMANCE = "api_performance"
    BUSINESS_METRICS = "business_metrics"
    EXTERNAL_SERVICES = "external_services"
    WEATHER = "weather"
    MARKET = "market"
    CUSTOMER_SENTIMENT = "customer_sentiment"


@dataclass
class SensorReading:
    """A reading from a sensor"""
    sensor_type: SensorType
    timestamp: datetime
    value: Any
    metadata: Dict[str, Any] = field(default_factory=dict)
    anomaly_score: float = 0.0  # 0-1, higher = more anomalous


@dataclass
class Alert:
    """An alert generated by the awareness system"""
    id: str
    severity: AlertSeverity
    alert_type: str
    message: str
    details: Dict[str, Any]
    timestamp: datetime
    acknowledged: bool = False
    resolved: bool = False
    resolution: Optional[str] = None


class AwarenessSystem:
    """
    Continuous Awareness System for BrainOps AI OS

    Provides:
    1. Real-time system health monitoring
    2. External environment sensing
    3. Business metrics tracking
    4. Anomaly detection
    5. Predictive alerting
    6. Sensory processing pipeline
    """

    def __init__(self, controller: "MetacognitiveController"):
        self.controller = controller
        self.db_pool: Optional[asyncpg.Pool] = None

        # Sensor readings buffer
        self.readings: Dict[SensorType, deque] = {
            sensor_type: deque(maxlen=1000)
            for sensor_type in SensorType
        }

        # Baselines for anomaly detection
        self.baselines: Dict[str, Dict[str, float]] = {}

        # Active alerts
        self.alerts: Dict[str, Alert] = {}
        self.alert_history: deque = deque(maxlen=10000)

        # Background task handles
        self._tasks: List[asyncio.Task] = []
        self._shutdown = asyncio.Event()

        # External API clients
        self._http_client: Optional[httpx.AsyncClient] = None

        # Metrics
        self.metrics = {
            "total_readings": 0,
            "anomalies_detected": 0,
            "alerts_generated": 0,
            "alerts_resolved": 0,
        }

    async def initialize(self, db_pool: asyncpg.Pool):
        """Initialize the awareness system"""
        self.db_pool = db_pool
        self._http_client = httpx.AsyncClient(timeout=30.0)

        # Create database tables
        try:
            await self._initialize_database()
        except Exception as e:
            if "permission denied" in str(e).lower():
                pass
            else:
                raise

        # Load existing baselines
        await self._load_baselines()

        # Start sensor loops
        await self._start_sensors()

        logger.info("AwarenessSystem initialized")

    async def _initialize_database(self):
        """Create required database tables"""
        async with self.db_pool.acquire() as conn:
            await conn.execute('''
                -- Sensor readings
                CREATE TABLE IF NOT EXISTS brainops_sensor_readings (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    sensor_type VARCHAR(50) NOT NULL,
                    reading_value JSONB NOT NULL,
                    anomaly_score FLOAT DEFAULT 0,
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT NOW()
                );
                CREATE INDEX IF NOT EXISTS idx_sensor_type
                    ON brainops_sensor_readings(sensor_type);
                CREATE INDEX IF NOT EXISTS idx_sensor_time
                    ON brainops_sensor_readings(created_at DESC);
                CREATE INDEX IF NOT EXISTS idx_sensor_anomaly
                    ON brainops_sensor_readings(anomaly_score)
                    WHERE anomaly_score > 0.5;

                -- Baselines for anomaly detection
                CREATE TABLE IF NOT EXISTS brainops_baselines (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    metric_name VARCHAR(100) UNIQUE NOT NULL,
                    baseline_mean FLOAT NOT NULL,
                    baseline_std FLOAT NOT NULL,
                    sample_count INT DEFAULT 0,
                    last_updated TIMESTAMP DEFAULT NOW()
                );

                -- Alerts
                CREATE TABLE IF NOT EXISTS brainops_alerts (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    alert_id VARCHAR(50) UNIQUE NOT NULL,
                    severity VARCHAR(20) NOT NULL,
                    alert_type VARCHAR(100) NOT NULL,
                    message TEXT NOT NULL,
                    details JSONB,
                    acknowledged BOOLEAN DEFAULT FALSE,
                    resolved BOOLEAN DEFAULT FALSE,
                    resolution TEXT,
                    created_at TIMESTAMP DEFAULT NOW(),
                    acknowledged_at TIMESTAMP,
                    resolved_at TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_alert_severity
                    ON brainops_alerts(severity);
                CREATE INDEX IF NOT EXISTS idx_alert_unresolved
                    ON brainops_alerts(resolved) WHERE resolved = FALSE;
            ''')

    async def _load_baselines(self):
        """Load existing baselines from database"""
        rows = await self._db_fetch_with_retry('''
            SELECT metric_name, baseline_mean, baseline_std, sample_count
            FROM brainops_baselines
        ''')

        for row in rows:
            self.baselines[row['metric_name']] = {
                'mean': row['baseline_mean'],
                'std': row['baseline_std'],
                'count': row['sample_count'],
            }

        logger.info(f"Loaded {len(self.baselines)} baselines")

    def _create_safe_task(self, coro, name: str = None) -> asyncio.Task:
        """Create an asyncio task with exception logging to prevent 'Task exception was never retrieved'."""
        task = asyncio.create_task(coro, name=name)

        def _on_done(t: asyncio.Task):
            if t.cancelled():
                return
            exc = t.exception()
            if exc is not None:
                logger.error("Background task %s failed: %s", t.get_name(), exc, exc_info=exc)

        task.add_done_callback(_on_done)
        return task

    async def _start_sensors(self):
        """Start all sensor loops"""
        # System health sensor - every 5 seconds
        self._tasks.append(
            self._create_safe_task(self._system_health_sensor(), name="system_health_sensor")
        )

        # Database sensor - every 10 seconds
        self._tasks.append(
            self._create_safe_task(self._database_sensor(), name="database_sensor")
        )

        # Business metrics sensor - every 30 seconds
        self._tasks.append(
            self._create_safe_task(self._business_metrics_sensor(), name="business_metrics_sensor")
        )

        # API performance sensor - every 15 seconds
        self._tasks.append(
            self._create_safe_task(self._api_performance_sensor(), name="api_performance_sensor")
        )

        # External services sensor - every 60 seconds
        self._tasks.append(
            self._create_safe_task(self._external_services_sensor(), name="external_services_sensor")
        )

        # Weather sensor - every 5 minutes
        self._tasks.append(
            self._create_safe_task(self._weather_sensor(), name="weather_sensor")
        )

        # Anomaly detection processor - every 30 seconds
        self._tasks.append(
            self._create_safe_task(self._anomaly_detection_loop(), name="anomaly_detection")
        )

        logger.info(f"Started {len(self._tasks)} sensor loops")

    # =========================================================================
    # SENSOR IMPLEMENTATIONS
    # =========================================================================

    async def _system_health_sensor(self):
        """Monitor system health metrics"""
        while not self._shutdown.is_set():
            try:
                # Collect system metrics
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                disk = psutil.disk_usage('/')

                reading = SensorReading(
                    sensor_type=SensorType.SYSTEM_HEALTH,
                    timestamp=datetime.now(),
                    value={
                        "cpu_percent": cpu_percent,
                        "memory_percent": memory.percent,
                        "memory_available_mb": memory.available / (1024 * 1024),
                        "disk_percent": disk.percent,
                        "disk_free_gb": disk.free / (1024 * 1024 * 1024),
                    }
                )

                # Detect anomalies
                reading.anomaly_score = await self._calculate_anomaly_score(
                    "system_health", reading.value
                )

                # Store reading
                await self._store_reading(reading)

                # Generate alerts if needed
                if cpu_percent > 90:
                    await self._generate_alert(
                        AlertSeverity.WARNING,
                        "high_cpu",
                        f"CPU usage at {cpu_percent}%",
                        reading.value
                    )

                if memory.percent > 90:
                    await self._generate_alert(
                        AlertSeverity.WARNING,
                        "high_memory",
                        f"Memory usage at {memory.percent}%",
                        reading.value
                    )

                if disk.percent > 90:
                    await self._generate_alert(
                        AlertSeverity.WARNING,
                        "low_disk",
                        f"Disk usage at {disk.percent}%",
                        reading.value
                    )

                await asyncio.sleep(5)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"System health sensor error: {e}")
                await asyncio.sleep(10)

    async def _database_sensor(self):
        """Monitor database health and performance"""
        while not self._shutdown.is_set():
            try:
                start_time = time.time()

                # Check connection health with retry
                await self._db_execute_with_retry("SELECT 1")
                query_time = (time.time() - start_time) * 1000

                # Get pool stats
                pool_size = self.db_pool.get_size()
                pool_free = self.db_pool.get_idle_size()

                # Get database stats with retry
                stats = await self._db_fetchrow_with_retry('''
                    SELECT
                        (SELECT COUNT(*) FROM pg_stat_activity
                         WHERE state = 'active') as active_connections,
                        (SELECT COUNT(*) FROM pg_stat_activity
                         WHERE state = 'idle') as idle_connections
                ''')

                reading = SensorReading(
                    sensor_type=SensorType.DATABASE,
                    timestamp=datetime.now(),
                    value={
                        "query_time_ms": query_time,
                        "pool_size": pool_size,
                        "pool_free": pool_free,
                        "active_connections": stats['active_connections'] if stats else 0,
                        "idle_connections": stats['idle_connections'] if stats else 0,
                    }
                )

                reading.anomaly_score = await self._calculate_anomaly_score(
                    "database", reading.value
                )

                await self._store_reading(reading)

                # Alert on slow queries
                if query_time > 1000:
                    await self._generate_alert(
                        AlertSeverity.WARNING,
                        "slow_database",
                        f"Database query took {query_time:.0f}ms",
                        reading.value
                    )

                await asyncio.sleep(10)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Database sensor error: {e}")
                await self._generate_alert(
                    AlertSeverity.CRITICAL,
                    "database_error",
                    f"Database sensor failed: {str(e)}",
                    {"error": str(e)}
                )
                await asyncio.sleep(30)

    async def _business_metrics_sensor(self):
        """Monitor business metrics"""
        while not self._shutdown.is_set():
            try:
                # Get recent lead count with retry
                lead_count = await self._db_fetchval_with_retry('''
                    SELECT COUNT(*) FROM leads
                    WHERE created_at > NOW() - INTERVAL '24 hours'
                ''') or 0

                # Get recent revenue with retry
                revenue = await self._db_fetchval_with_retry('''
                    SELECT COALESCE(SUM(amount), 0) FROM transactions
                    WHERE created_at > NOW() - INTERVAL '24 hours'
                    AND status = 'completed'
                ''') or 0

                # Get active jobs with retry
                active_jobs = await self._db_fetchval_with_retry('''
                    SELECT COUNT(*) FROM jobs
                    WHERE status IN ('pending', 'in_progress', 'scheduled')
                ''') or 0

                # Get customer count with retry
                customer_count = await self._db_fetchval_with_retry('''
                    SELECT COUNT(*) FROM customers
                    WHERE status = 'active'
                ''') or 0

                reading = SensorReading(
                    sensor_type=SensorType.BUSINESS_METRICS,
                    timestamp=datetime.now(),
                    value={
                        "leads_24h": lead_count,
                        "revenue_24h": float(revenue),
                        "active_jobs": active_jobs,
                        "active_customers": customer_count,
                    }
                )

                reading.anomaly_score = await self._calculate_anomaly_score(
                    "business", reading.value
                )

                await self._store_reading(reading)

                # Alert on unusual activity
                if reading.anomaly_score > 0.8:
                    await self._generate_alert(
                        AlertSeverity.INFO,
                        "business_anomaly",
                        "Unusual business activity detected",
                        reading.value
                    )

                await asyncio.sleep(30)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Business metrics sensor error: {e}")
                await asyncio.sleep(60)

    async def _api_performance_sensor(self):
        """Monitor API performance metrics"""
        while not self._shutdown.is_set():
            try:
                # Get recent API metrics with retry
                metrics = await self._db_fetchrow_with_retry('''
                    SELECT
                        COUNT(*) as request_count,
                        AVG(duration_ms) as avg_duration_ms,
                        MAX(duration_ms) as max_duration_ms,
                        SUM(CASE WHEN status_code >= 500 THEN 1 ELSE 0 END) as error_count
                    FROM api_metrics
                    WHERE timestamp > NOW() - INTERVAL '5 minutes'
                ''')

                if metrics:
                    reading = SensorReading(
                        sensor_type=SensorType.API_PERFORMANCE,
                        timestamp=datetime.now(),
                        value={
                            "request_count_5m": metrics['request_count'] or 0,
                            "avg_response_time_ms": float(metrics['avg_duration_ms'] or 0),
                            "max_response_time_ms": float(metrics['max_duration_ms'] or 0),
                            "error_count_5m": metrics['error_count'] or 0,
                        }
                    )

                    reading.anomaly_score = await self._calculate_anomaly_score(
                        "api", reading.value
                    )

                    await self._store_reading(reading)

                    # Alert on high error rate
                    if metrics['request_count'] and metrics['error_count']:
                        error_rate = metrics['error_count'] / metrics['request_count']
                        if error_rate > 0.05:  # 5% error rate
                            await self._generate_alert(
                                AlertSeverity.WARNING,
                                "high_api_errors",
                                f"API error rate at {error_rate*100:.1f}%",
                                reading.value
                            )

                await asyncio.sleep(15)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"API performance sensor error: {e}")
                await asyncio.sleep(30)

    async def _external_services_sensor(self):
        """Monitor external service health"""
        while not self._shutdown.is_set():
            try:
                services = {
                    "stripe": "https://api.stripe.com/v1/health",
                    "sendgrid": "https://status.sendgrid.com/api/v2/status.json",
                    "supabase": os.getenv("SUPABASE_URL", "") + "/rest/v1/",
                }

                statuses = {}
                for service_name, url in services.items():
                    if not url:
                        continue
                    try:
                        start = time.time()
                        response = await self._http_client.get(url, timeout=10)
                        latency = (time.time() - start) * 1000
                        statuses[service_name] = {
                            "status": "up" if response.status_code < 500 else "degraded",
                            "latency_ms": latency,
                            "status_code": response.status_code,
                        }
                    except Exception as e:
                        statuses[service_name] = {
                            "status": "down",
                            "error": str(e),
                        }

                reading = SensorReading(
                    sensor_type=SensorType.EXTERNAL_SERVICES,
                    timestamp=datetime.now(),
                    value=statuses
                )

                await self._store_reading(reading)

                # Alert on service issues
                for service_name, status in statuses.items():
                    if status.get("status") == "down":
                        await self._generate_alert(
                            AlertSeverity.WARNING,
                            f"service_down_{service_name}",
                            f"External service {service_name} is down",
                            status
                        )

                await asyncio.sleep(60)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"External services sensor error: {e}")
                await asyncio.sleep(120)

    async def _weather_sensor(self):
        """Monitor weather for scheduling optimization"""
        while not self._shutdown.is_set():
            try:
                # This would integrate with a real weather API
                # For now, we'll check if we have location data and skip if no API key

                weather_api_key = os.getenv("WEATHER_API_KEY")
                if weather_api_key:
                    # Would call weather API here
                    pass

                reading = SensorReading(
                    sensor_type=SensorType.WEATHER,
                    timestamp=datetime.now(),
                    value={
                        "status": "no_api_key" if not weather_api_key else "ok",
                    }
                )

                await self._store_reading(reading)

                await asyncio.sleep(300)  # 5 minutes

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Weather sensor error: {e}")
                await asyncio.sleep(600)

    # =========================================================================
    # ANOMALY DETECTION
    # =========================================================================

    async def _anomaly_detection_loop(self):
        """Process readings for anomaly detection"""
        while not self._shutdown.is_set():
            try:
                # Update baselines with recent data
                await self._update_baselines()

                await asyncio.sleep(30)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Anomaly detection error: {e}")
                await asyncio.sleep(60)

    async def _calculate_anomaly_score(
        self,
        category: str,
        values: Dict[str, Any]
    ) -> float:
        """Calculate anomaly score for a reading"""
        scores = []

        for key, value in values.items():
            if not isinstance(value, (int, float)):
                continue

            metric_name = f"{category}_{key}"
            baseline = self.baselines.get(metric_name)

            if baseline and baseline['std'] > 0:
                # Z-score calculation
                z_score = abs(value - baseline['mean']) / baseline['std']
                # Convert to 0-1 score (sigmoid-like)
                score = min(1.0, z_score / 5.0)
                scores.append(score)

        return max(scores) if scores else 0.0

    async def _update_baselines(self):
        """Update baselines with recent data"""
        # Get recent readings for baseline calculation (with retry)
        rows = await self._db_fetch_with_retry('''
            SELECT sensor_type, reading_value
            FROM brainops_sensor_readings
            WHERE created_at > NOW() - INTERVAL '24 hours'
        ''')

        # Aggregate values by metric
        metric_values: Dict[str, List[float]] = {}

        for row in rows:
            sensor_type = row['sensor_type']
            values = row['reading_value']

            if isinstance(values, dict):
                for key, value in values.items():
                    if isinstance(value, (int, float)):
                        metric_name = f"{sensor_type}_{key}"
                        if metric_name not in metric_values:
                            metric_values[metric_name] = []
                        metric_values[metric_name].append(float(value))

        # Update baselines
        for metric_name, values in metric_values.items():
            if len(values) < 10:
                continue

            import numpy as np
            mean = np.mean(values)
            std = np.std(values)

            self.baselines[metric_name] = {
                'mean': mean,
                'std': max(std, 0.001),  # Avoid division by zero
                'count': len(values),
            }

            # Persist to database (with retry)
            await self._db_execute_with_retry('''
                INSERT INTO brainops_baselines
                (metric_name, baseline_mean, baseline_std, sample_count, last_updated)
                VALUES ($1, $2, $3, $4, NOW())
                ON CONFLICT (metric_name) DO UPDATE SET
                    baseline_mean = EXCLUDED.baseline_mean,
                    baseline_std = EXCLUDED.baseline_std,
                    sample_count = EXCLUDED.sample_count,
                    last_updated = NOW()
            ''', metric_name, mean, std, len(values))

    # =========================================================================
    # ALERT MANAGEMENT
    # =========================================================================

    async def _generate_alert(
        self,
        severity: AlertSeverity,
        alert_type: str,
        message: str,
        details: Dict[str, Any]
    ):
        """Generate a new alert"""
        # Check for duplicate active alerts
        alert_key = f"{alert_type}_{severity.value}"
        if alert_key in self.alerts and not self.alerts[alert_key].resolved:
            return  # Don't duplicate

        import uuid
        alert_id = str(uuid.uuid4())

        alert = Alert(
            id=alert_id,
            severity=severity,
            alert_type=alert_type,
            message=message,
            details=details,
            timestamp=datetime.now(),
        )

        self.alerts[alert_key] = alert
        self.alert_history.append(alert)
        self.metrics["alerts_generated"] += 1

        # Store in database (with retry)
        await self._db_execute_with_retry('''
            INSERT INTO brainops_alerts
            (alert_id, severity, alert_type, message, details)
            VALUES ($1, $2, $3, $4, $5)
        ''', alert_id, severity.value, alert_type, message, json.dumps(details))

        # Notify controller
        if self.controller and severity in [AlertSeverity.CRITICAL, AlertSeverity.WARNING]:
            from .metacognitive_controller import AttentionPriority
            await self.controller._record_thought({
                "type": "alert",
                "severity": severity.value,
                "alert_type": alert_type,
                "message": message,
                "details": details,
            }, AttentionPriority.CRITICAL if severity == AlertSeverity.CRITICAL else AttentionPriority.URGENT,
            "awareness_system")

        logger.warning(f"Alert generated: [{severity.value}] {alert_type}: {message}")

    async def acknowledge_alert(self, alert_id: str) -> bool:
        """Acknowledge an alert"""
        for key, alert in self.alerts.items():
            if alert.id == alert_id:
                alert.acknowledged = True
                await self._db_execute_with_retry('''
                    UPDATE brainops_alerts
                    SET acknowledged = TRUE, acknowledged_at = NOW()
                    WHERE alert_id = $1
                ''', alert_id)
                return True
        return False

    async def resolve_alert(self, alert_id: str, resolution: str) -> bool:
        """Resolve an alert"""
        for key, alert in self.alerts.items():
            if alert.id == alert_id:
                alert.resolved = True
                alert.resolution = resolution
                self.metrics["alerts_resolved"] += 1

                await self._db_execute_with_retry('''
                    UPDATE brainops_alerts
                    SET resolved = TRUE, resolution = $2, resolved_at = NOW()
                    WHERE alert_id = $1
                ''', alert_id, resolution)
                return True
        return False

    async def get_critical_alerts(self) -> List[Dict[str, Any]]:
        """Get all unresolved critical alerts"""
        return [
            {
                "id": alert.id,
                "type": alert.alert_type,
                "message": alert.message,
                "details": alert.details,
                "timestamp": alert.timestamp.isoformat(),
            }
            for alert in self.alerts.values()
            if alert.severity == AlertSeverity.CRITICAL and not alert.resolved
        ]

    async def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Get all active (unresolved) alerts"""
        return [
            {
                "id": alert.id,
                "severity": alert.severity.value,
                "type": alert.alert_type,
                "message": alert.message,
                "details": alert.details,
                "timestamp": alert.timestamp.isoformat(),
                "acknowledged": alert.acknowledged,
            }
            for alert in self.alerts.values()
            if not alert.resolved
        ]

    # =========================================================================
    # STORAGE
    # =========================================================================

    async def _db_execute_with_retry(self, query: str, *args, max_retries: int = 2):
        """Execute a database query with retry on connection errors."""
        last_error = None
        for attempt in range(max_retries + 1):
            try:
                async with self.db_pool.acquire() as conn:
                    return await conn.execute(query, *args)
            except (
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                asyncpg.InternalClientError,
                asyncpg.PostgresConnectionError,
            ) as e:
                last_error = e
                if attempt < max_retries:
                    await asyncio.sleep(0.2 * (attempt + 1))
                else:
                    raise
            except asyncio.CancelledError:
                raise
        if last_error:
            raise last_error

    async def _db_fetch_with_retry(self, query: str, *args, max_retries: int = 2):
        """Fetch database rows with retry on connection errors."""
        last_error = None
        for attempt in range(max_retries + 1):
            try:
                async with self.db_pool.acquire() as conn:
                    return await conn.fetch(query, *args)
            except (
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                asyncpg.InternalClientError,
                asyncpg.PostgresConnectionError,
            ) as e:
                last_error = e
                if attempt < max_retries:
                    await asyncio.sleep(0.2 * (attempt + 1))
                else:
                    raise
            except asyncio.CancelledError:
                raise
        if last_error:
            raise last_error

    async def _db_fetchrow_with_retry(self, query: str, *args, max_retries: int = 2):
        """Fetch single database row with retry on connection errors."""
        last_error = None
        for attempt in range(max_retries + 1):
            try:
                async with self.db_pool.acquire() as conn:
                    return await conn.fetchrow(query, *args)
            except (
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                asyncpg.InternalClientError,
                asyncpg.PostgresConnectionError,
            ) as e:
                last_error = e
                if attempt < max_retries:
                    await asyncio.sleep(0.2 * (attempt + 1))
                else:
                    raise
            except asyncio.CancelledError:
                raise
        if last_error:
            raise last_error

    async def _db_fetchval_with_retry(self, query: str, *args, max_retries: int = 2):
        """Fetch single database value with retry on connection errors."""
        last_error = None
        for attempt in range(max_retries + 1):
            try:
                async with self.db_pool.acquire() as conn:
                    return await conn.fetchval(query, *args)
            except (
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                asyncpg.InternalClientError,
                asyncpg.PostgresConnectionError,
            ) as e:
                last_error = e
                if attempt < max_retries:
                    await asyncio.sleep(0.2 * (attempt + 1))
                else:
                    raise
            except asyncio.CancelledError:
                raise
        if last_error:
            raise last_error

    async def _store_reading(self, reading: SensorReading):
        """Store a sensor reading"""
        self.readings[reading.sensor_type].append(reading)
        self.metrics["total_readings"] += 1

        if reading.anomaly_score > 0.5:
            self.metrics["anomalies_detected"] += 1

        await self._db_execute_with_retry('''
            INSERT INTO brainops_sensor_readings
            (sensor_type, reading_value, anomaly_score, metadata)
            VALUES ($1, $2, $3, $4)
        ''',
            reading.sensor_type.value,
            json.dumps(reading.value),
            reading.anomaly_score,
            json.dumps(reading.metadata)
        )

    # =========================================================================
    # PUBLIC API
    # =========================================================================

    async def handle_alert(self, alert_data: Dict[str, Any]) -> Dict[str, Any]:
        """Handle an incoming alert from the controller"""
        severity = AlertSeverity(alert_data.get("severity", "info"))
        await self._generate_alert(
            severity,
            alert_data.get("type", "external"),
            alert_data.get("message", "External alert"),
            alert_data.get("details", {})
        )
        return {"status": "alert_created"}

    async def get_health(self) -> Dict[str, Any]:
        """Get awareness system health status"""
        active_tasks = sum(1 for t in self._tasks if not t.done())

        return {
            "status": "healthy" if active_tasks == len(self._tasks) else "degraded",
            "score": active_tasks / len(self._tasks) if self._tasks else 1.0,
            "active_sensors": active_tasks,
            "total_sensors": len(self._tasks),
            "metrics": self.metrics.copy(),
            "active_alerts": len([a for a in self.alerts.values() if not a.resolved]),
        }

    async def get_latest_readings(self, sensor_type: Optional[SensorType] = None) -> Dict[str, Any]:
        """Get latest sensor readings"""
        result = {}

        types_to_check = [sensor_type] if sensor_type else list(SensorType)

        for st in types_to_check:
            readings = self.readings.get(st, deque())
            if readings:
                latest = readings[-1]
                result[st.value] = {
                    "value": latest.value,
                    "timestamp": latest.timestamp.isoformat(),
                    "anomaly_score": latest.anomaly_score,
                }

        return result

    async def shutdown(self):
        """Shutdown the awareness system"""
        self._shutdown.set()

        for task in self._tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass

        if self._http_client:
            await self._http_client.aclose()

        logger.info("AwarenessSystem shutdown complete")


# Singleton
_awareness_system: Optional[AwarenessSystem] = None


def get_awareness_system() -> Optional[AwarenessSystem]:
    """Get the awareness system instance"""
    return _awareness_system
