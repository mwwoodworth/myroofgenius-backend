"""
Central Nervous System (CNS) Service - Simplified Version
Works with database tables and provides intelligent fallbacks when AI unavailable
"""

import asyncio
import asyncpg
import json
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, HTTPException, Depends
import logging
import hashlib

logger = logging.getLogger(__name__)

class BrainOpsCNS:
    """Central Nervous System - The brain of our operations"""

    def __init__(self, db_pool: asyncpg.Pool = None):
        """Initialize CNS with database pool"""
        self.db_pool = db_pool
        self.initialized = False

    async def initialize(self):
        """Initialize CNS and verify database tables"""
        if not self.db_pool:
            raise Exception("Database pool not provided")

        try:
            # Verify CNS tables exist
            async with self.db_pool.acquire() as conn:
                tables = await conn.fetch("""
                    SELECT table_name FROM information_schema.tables
                    WHERE table_schema = 'public'
                    AND table_name LIKE 'cns_%'
                """)

                if len(tables) < 9:
                    raise Exception(f"CNS tables missing. Found {len(tables)}/9 tables")

                self.initialized = True
                logger.info(f"âœ… CNS initialized with {len(tables)} tables")
                return True

        except Exception as e:
            logger.error(f"CNS initialization failed: {e}")
            raise

    def _generate_embedding(self, text: str) -> List[float]:
        """Generate a deterministic embedding from text (fallback when no AI)"""
        # Use SHA256 to generate deterministic values from text
        hash_obj = hashlib.sha256(text.encode())
        hash_hex = hash_obj.hexdigest()

        # Convert hex to floats between -1 and 1
        embedding = []
        for i in range(0, min(len(hash_hex), 1536*2), 2):
            hex_pair = hash_hex[i:i+2]
            value = (int(hex_pair, 16) / 127.5) - 1.0  # Normalize to [-1, 1]
            embedding.append(value)

        # Pad to 1536 dimensions if needed
        while len(embedding) < 1536:
            embedding.append(0.0)

        return embedding[:1536]

    async def remember(self, data: Dict) -> str:
        """Store anything in permanent memory"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            # Generate embedding from full payload
            text = json.dumps(data)
            embedding = self._generate_embedding(text)

            # Serialize content to JSON string to match TEXT columns safely.
            content_str = json.dumps(data)

            # Store in database
            result = await conn.fetchval("""
                INSERT INTO cns_memory (
                    memory_type, category, title, content,
                    embedding, importance_score, tags
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
                RETURNING memory_id
            """,
                data.get('type', 'general'),
                data.get('category', 'system'),
                data.get('title', 'Memory'),
                content_str,
                embedding,
                data.get('importance', 0.5),
                data.get('tags', [])
            )

            logger.info(f"ðŸ’¾ Stored memory: {result}")
            return str(result)

    async def recall(self, query: str, limit: int = 10) -> List[Dict]:
        """Retrieve relevant memories using semantic search"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            # Generate query embedding
            query_embedding = self._generate_embedding(query)

            # Search with vector similarity (using cosine distance)
            results = await conn.fetch("""
                SELECT
                    memory_id, memory_type, category, title, content,
                    importance_score, tags, created_at,
                    1 - (embedding <=> $1::vector) as similarity
                FROM cns_memory
                WHERE expires_at IS NULL OR expires_at > NOW()
                ORDER BY similarity DESC, importance_score DESC
                LIMIT $2
            """, query_embedding, limit)

            # Update access count
            memory_ids = [r['memory_id'] for r in results]
            if memory_ids:
                await conn.execute("""
                    UPDATE cns_memory
                    SET accessed_count = accessed_count + 1,
                        last_accessed = NOW()
                    WHERE memory_id = ANY($1)
                """, memory_ids)

            return [dict(r) for r in results]

    async def create_task(self, task: Dict) -> str:
        """Create a new task with AI-calculated priority"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            # Calculate priority intelligently
            urgency = self._calculate_urgency(task)
            importance = self._calculate_importance(task)
            priority = (urgency * 0.6 + importance * 0.4)

            result = await conn.fetchval("""
                INSERT INTO cns_tasks (
                    title, description, priority, urgency, importance,
                    status, tags, metadata, due_date
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                RETURNING task_id
            """,
                task.get('title', 'New Task'),
                task.get('description', ''),
                priority,
                urgency,
                importance,
                'pending',
                task.get('tags', []),
                task,
                task.get('due_date')
            )

            logger.info(f"ðŸ“‹ Created task: {result} (priority: {priority:.2f})")
            return str(result)

    def _calculate_urgency(self, task: Dict) -> float:
        """Calculate urgency based on due date and keywords"""
        urgency = 0.5

        # Check for urgent keywords
        urgent_keywords = ['urgent', 'asap', 'critical', 'emergency', 'now', 'immediate']
        text = f"{task.get('title', '')} {task.get('description', '')}".lower()

        for keyword in urgent_keywords:
            if keyword in text:
                urgency = max(urgency, 0.9)
                break

        # Check due date
        if task.get('due_date'):
            # Would calculate based on time until due
            urgency = max(urgency, 0.7)

        return urgency

    def _calculate_importance(self, task: Dict) -> float:
        """Calculate importance based on impact and keywords"""
        importance = 0.5

        # Check for important keywords
        important_keywords = ['revenue', 'customer', 'production', 'security', 'compliance']
        text = f"{task.get('title', '')} {task.get('description', '')}".lower()

        for keyword in important_keywords:
            if keyword in text:
                importance = max(importance, 0.8)

        return importance

    async def get_tasks(self, status: Optional[str] = None) -> List[Dict]:
        """Get tasks, optionally filtered by status"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            if status:
                results = await conn.fetch("""
                    SELECT * FROM cns_tasks
                    WHERE status = $1
                    ORDER BY priority DESC, created_at DESC
                    LIMIT 100
                """, status)
            else:
                results = await conn.fetch("""
                    SELECT * FROM cns_tasks
                    ORDER BY priority DESC, created_at DESC
                    LIMIT 100
                """)

            return [dict(r) for r in results]

    async def update_task_status(self, task_id: str, status: str) -> bool:
        """Update task status"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            result = await conn.execute("""
                UPDATE cns_tasks
                SET status = $1, updated_at = NOW()
                WHERE task_id = $2
            """, status, task_id)

            return result != "UPDATE 0"

    async def get_status(self) -> Dict:
        """Get CNS system status"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            # Get counts
            memory_count = await conn.fetchval("SELECT COUNT(*) FROM cns_memory")
            task_count = await conn.fetchval("SELECT COUNT(*) FROM cns_tasks WHERE status != 'completed'")
            project_count = await conn.fetchval("SELECT COUNT(*) FROM cns_projects WHERE status = 'active'")

            # Get recent activity
            recent_memories = await conn.fetchval("""
                SELECT COUNT(*) FROM cns_memory
                WHERE created_at > NOW() - INTERVAL '24 hours'
            """)

            return {
                "status": "operational",
                "initialized": self.initialized,
                "memory_count": memory_count,
                "task_count": task_count,
                "project_count": project_count,
                "recent_memories": recent_memories,
                "database": "connected",
                "ai_provider": "fallback (no API keys)",
                "vector_search": "enabled (pgvector)",
                "version": "v135.0.0"
            }

    async def learn(self, pattern: Dict) -> bool:
        """Record a learning pattern"""
        if not self.initialized:
            await self.initialize()

        async with self.db_pool.acquire() as conn:
            # Check if similar pattern exists
            existing = await conn.fetchval("""
                SELECT pattern_id FROM cns_learning_patterns
                WHERE pattern_type = $1
                AND pattern_data->>'key' = $2
            """, pattern.get('type'), pattern.get('key'))

            if existing:
                # Update existing pattern
                await conn.execute("""
                    UPDATE cns_learning_patterns
                    SET occurrences = occurrences + 1,
                        confidence = LEAST(confidence + 0.05, 1.0),
                        last_observed = NOW()
                    WHERE pattern_id = $1
                """, existing)
            else:
                # Create new pattern
                await conn.execute("""
                    INSERT INTO cns_learning_patterns (
                        pattern_type, pattern_data, confidence
                    ) VALUES ($1, $2, $3)
                """, pattern.get('type', 'behavior'), pattern, 0.5)

            return True

    async def decide(self, context: str, options: List[str]) -> Dict:
        """Make a decision based on context and past learning"""
        if not self.initialized:
            await self.initialize()

        # Simple decision logic without AI
        # Score each option based on past patterns
        scores = {}
        for option in options:
            # Look for similar past decisions
            score = 0.5  # Base score

            # Boost score based on keywords
            if 'recommended' in option.lower():
                score += 0.2
            if 'safe' in option.lower():
                score += 0.1
            if 'fast' in option.lower():
                score += 0.1

            scores[option] = min(score, 1.0)

        # Choose best option
        best_option = max(scores, key=scores.get)

        # Record decision
        async with self.db_pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO cns_decisions (
                    context, question, options, chosen_option,
                    reasoning, confidence_score
                ) VALUES ($1, $2, $3, $4, $5, $6)
            """,
                context,
                "Which option to choose?",
                json.dumps(options),
                json.dumps({"choice": best_option, "score": scores[best_option]}),
                f"Chose based on scoring algorithm: {scores}",
                scores[best_option]
            )

        return {
            "decision": best_option,
            "confidence": scores[best_option],
            "reasoning": f"Best score among options",
            "scores": scores
        }

def create_cns_routes(cns: BrainOpsCNS) -> APIRouter:
    """Create FastAPI routes for CNS"""
    router = APIRouter()

    @router.get("/status")
    async def get_status():
        """Get CNS system status"""
        return await cns.get_status()

    @router.post("/memory")
    async def store_memory(data: Dict):
        """Store a memory"""
        memory_id = await cns.remember(data)
        return {"memory_id": memory_id, "status": "stored"}

    @router.get("/memory/search")
    async def search_memory(query: str, limit: int = 10):
        """Search memories"""
        results = await cns.recall(query, limit)
        return {"query": query, "results": results, "count": len(results)}

    @router.post("/tasks")
    async def create_task(task: Dict):
        """Create a task"""
        task_id = await cns.create_task(task)
        return {"task_id": task_id, "status": "created"}

    @router.get("/tasks")
    async def get_tasks(status: Optional[str] = None):
        """Get tasks"""
        tasks = await cns.get_tasks(status)
        return {"tasks": tasks, "count": len(tasks)}

    @router.put("/tasks/{task_id}/status")
    async def update_task(task_id: str, status: str):
        """Update task status"""
        success = await cns.update_task_status(task_id, status)
        return {"success": success}

    @router.post("/learn")
    async def learn_pattern(pattern: Dict):
        """Record a learning pattern"""
        success = await cns.learn(pattern)
        return {"success": success}

    @router.post("/decide")
    async def make_decision(context: str, options: List[str]):
        """Make a decision"""
        decision = await cns.decide(context, options)
        return decision

    return router
